{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import folktables\n",
    "from folktables import ACSDataSource, ACSEmployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_converged(x, size, epsilon):\n",
    "    for i in range(0,size):\n",
    "            if np.linalg.norm(x[-1:][0] - x[-(2+i):][0], np.inf) > epsilon:\n",
    "                return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_proxies(x, y, z, iters, epsilon, eta_val=None):\n",
    "    r = 100\n",
    "    treshold = 0.01\n",
    "    n = x.shape[0]\n",
    "    theta = [np.round(LinearRegression(fit_intercept=False).fit(x,z).coef_.reshape(-1,1),10)]\n",
    "    #theta = [np.random.rand(d,1)]\n",
    "    grad_l = [0]\n",
    "    theta_average = theta\n",
    "    converged = False\n",
    "    if eta_val:\n",
    "        eta = eta_val\n",
    "    print(\"Iterations:\")\n",
    "    \n",
    "    for t in range(1, iters):\n",
    "        if eta_val is None:\n",
    "            eta = 1/np.sqrt(t)\n",
    "            \n",
    "        if converged:\n",
    "            print(\"Converged\")\n",
    "            break\n",
    "            \n",
    "        if t%200 == 0:\n",
    "            print(t)\n",
    "        \n",
    "        zhat = np.round(np.matmul(x,theta[t-1]),r)\n",
    "        costs = np.round((zhat-z),r)*(1-2*y)\n",
    "        \n",
    "        prc_1 = LinearRegression(fit_intercept=False).fit(x,costs)\n",
    "        prc_2 = LinearRegression(fit_intercept=False).fit(x,-costs)\n",
    "        h_s_1 = np.round(prc_1.predict(x),r)\n",
    "        h_s_2 = np.round(prc_2.predict(x),r)\n",
    "        \n",
    "        #Use matmul, numerical precision error\n",
    "        h_1 = (h_s_1 > 0)       \n",
    "        h_2 = (h_s_2 > 0)\n",
    "    \n",
    "        if np.sum(h_s_1[h_1]) > np.sum(h_s_2[h_2]):\n",
    "            h = h_1\n",
    "        else:\n",
    "            h = h_2\n",
    "\n",
    "        h = h.astype(int)\n",
    "        zhat_sum = np.sum(zhat)\n",
    "        z_sum = np.sum(z)\n",
    "        err_points = np.round(np.abs(h-y))\n",
    "       \n",
    "        [[err_cost]] = np.matmul(np.round((zhat-z).T,r),err_points)\n",
    "        overall_diff = (zhat_sum/z_sum) - 1\n",
    "        #Add in break statement for very small costs\n",
    "        \n",
    "        if np.abs(overall_diff) >= np.abs(err_cost):           \n",
    "            penalty = np.sign(overall_diff) * np.sum(x, axis=0)/z_sum\n",
    "            penalty = eta*penalty.reshape(-1,1)\n",
    "        else:\n",
    "            penalty = np.sign(err_cost) * np.matmul(np.transpose(x),err_points) \n",
    "            penalty = eta*penalty.reshape(-1,1)\n",
    "\n",
    "        grad_l.append(penalty)\n",
    "        new_theta = (theta[t-1] - grad_l[t])\n",
    "\n",
    "        theta.append(new_theta)\n",
    "        theta_average.append((t*theta_average[t-1]+theta[t])/(t+1))\n",
    "        \n",
    "        if t%100 == 0 :\n",
    "            if has_converged(theta_average, 10, epsilon):\n",
    "                converged = True\n",
    "                    \n",
    "    return theta, grad_l, theta_average[-1]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_proxy(x, y, z, theta_average):\n",
    "    n = x.shape[0]\n",
    "    zhat = np.matmul(x, theta_average) \n",
    "    final_costs = (zhat-z)*(1-2*y)\n",
    "    prc = LinearRegression(fit_intercept=False).fit(x, final_costs)  \n",
    "    h_s = prc.predict(x)\n",
    "    h_plus = (h_s > 0)\n",
    "    h_minus = (h_s < 0)\n",
    "    \n",
    "    if np.sum(h_s[h_plus]) > -np.sum(h_s[h_minus]):\n",
    "        h = h_plus\n",
    "    else:\n",
    "        h = h_minus\n",
    "    \n",
    "    h = h.astype(int)    \n",
    "       \n",
    "    zhat_sum = np.sum(zhat)\n",
    "    z_sum = np.sum(z)\n",
    "    err_points = np.abs(h-y)\n",
    "\n",
    "    [[err_cost_z]] = np.matmul(z.T, err_points)\n",
    "    [[err_cost_zhat]] = np.matmul(zhat.T, err_points)\n",
    "    overall_diff = (zhat_sum/z_sum) - 1\n",
    "    model_diff = (err_cost_zhat - err_cost_z)\n",
    "    proxy_error = err_cost_zhat/zhat_sum - err_cost_z/z_sum\n",
    "    \n",
    "    return overall_diff, model_diff, proxy_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I. Census Data Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = ACSDataSource(survey_year='2018', horizon='1-Year', survey='person')\n",
    "acs_data = data_source.get_data(states=[\"CA\"], download=False)\n",
    "features, label, group = ACSEmployment.df_to_numpy(acs_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw_indices = (group<3)\n",
    "\n",
    "X_train, X_test, y_train, y_test, group_train, group_test = train_test_split(\n",
    "    features[bw_indices,:], label[bw_indices], group[bw_indices]-1, test_size=0.30, random_state=0)\n",
    "\n",
    "#Normalize feature matrix\n",
    "intercept = np.ones(X_train.shape[0]).reshape(-1,1)\n",
    "y = y_train.astype(int).reshape(-1,1)\n",
    "z = group_train.reshape(-1,1)\n",
    "x = np.hstack((intercept,X_train))\n",
    "\n",
    "coefficients, gradients, theta_average = linear_proxies(x, y, z, 1000, 0.001)\n",
    "overall_diff, model_diff, proxy_error = evaluate_proxy(x,y,z,theta_average)\n",
    "\n",
    "print(\"Overall diff: \" + str(overall_diff))\n",
    "print(\"Model diff: \" + str(model_diff))\n",
    "print(\"Proxy error: \" + str(proxy_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.matmul(x,theta_average)-z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "II. Synthetic Data Experimental Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthetic_proxy_experiments(T, trials, n, d, epsilon, eta, unit=False):\n",
    "    discrepancy_proxy = []\n",
    "    discrepancy_total = []\n",
    "    discrepancy_h = []\n",
    "    intercept = np.ones(n).reshape(-1,1)\n",
    "    \n",
    "    for i in range(0,trials):\n",
    "        np.random.seed(i)\n",
    "        y = np.round(np.random.rand(n,1))\n",
    "        \n",
    "        if unit:\n",
    "            theta = np.random.rand(d,1)\n",
    "            theta = theta/np.linalg.norm(theta)\n",
    "            x = np.random.rand(n,d)\n",
    "            \n",
    "            for j in range(0,n):\n",
    "                x[j,:] = x[j,:]/np.linalg.norm(x[j,:])\n",
    "                \n",
    "            zhat = np.matmul(x,theta)\n",
    "            z = np.random.binomial(n=n,p=zhat)   \n",
    "            \n",
    "        else:\n",
    "            z = np.round(np.random.rand(n,n))\n",
    "            theta = np.random.rand(n,n)\n",
    "            x = np.matmul(z, np.linalg.inv(theta))\n",
    "            x = np.hstack((intercept, x))\n",
    "            z = z[:,0].reshape(-1,1)\n",
    "\n",
    "        coefficients, gradients, theta_average = linear_proxies(x, y, z, T, epsilon, eta)\n",
    "        overall_diff, model_diff, proxy_error = evaluate_proxy(x,y,z,theta_average)\n",
    "       \n",
    "        discrepancy_total.append(overall_diff)\n",
    "        discrepancy_h.append(model_diff)\n",
    "        discrepancy_proxy.append(proxy_error)\n",
    "        \n",
    "    return discrepancy_total, discrepancy_h, discrepancy_proxy"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "n = 1000\n",
    "d = 100\n",
    "trials = 100\n",
    "\n",
    "d_proxy = []\n",
    "d_total = []\n",
    "d_h = []\n",
    "etas = [0.01, 0.001, 0.0001]\n",
    "iterations = [1000]\n",
    "epsilon = 0.01\n",
    "\n",
    "for iteration in iterations:\n",
    "    for eta in etas:\n",
    "        total, h, proxy = synthetic_proxy_experiments(iteration, trials, n, epsilon, eta, unit = True)\n",
    "        d_total.append(total)\n",
    "        d_proxy.append(proxy)\n",
    "        d_h.append(h)\n",
    "\n",
    "plt.hist(d_proxy, bins=100)\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Proxy Error\")\n",
    "plt.xlabel(\"Error\")\n",
    "plt.legend(etas)\n",
    "\n",
    "plt.figure(figsize=(16,12))\n",
    "plt.subplot(2,2,1)\n",
    "plt.hist(d_h)\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Greatest Error Region\")\n",
    "plt.xlabel(\"Error\")\n",
    "plt.legend(etas)\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.hist(d_total)\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Deviation of Average Values\")\n",
    "plt.xlabel(\"Error\")\n",
    "plt.legend(etas)\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.hist(d_proxy)\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Proxy Error\")\n",
    "plt.xlabel(\"Error\")\n",
    "plt.legend(etas)\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.hist(np.subtract(d_total,d_h))\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Error Region - Deviation of Average Values\")\n",
    "plt.xlabel(\"Error\")\n",
    "plt.legend(etas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
