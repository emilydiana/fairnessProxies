{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91ad9782",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import folktables\n",
    "from folktables import ACSDataSource, ACSEmployment\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ed41bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_converged(x, size, epsilon):\n",
    "    for i in range(0,size):\n",
    "            if np.linalg.norm(x[-1:][0] - x[-(2+i):][0], np.inf) > epsilon:\n",
    "                return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad7e1429",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_proxies(x, y, z, iters, epsilon, eta_val = None, non_disclosive=False, MSE=False):\n",
    "    n = x.shape[0]\n",
    "    theta = [LinearRegression(fit_intercept=False).fit(x,z).coef_.reshape(-1,1)]\n",
    "    theta_average = [LinearRegression(fit_intercept=False).fit(x,z).coef_.reshape(-1,1)]\n",
    "    z_sum = np.sum(z)\n",
    "    grad_term_overall = np.sum(x, axis=0)/z_sum\n",
    "    converged = False\n",
    "    \n",
    "    if eta_val:\n",
    "        eta = eta_val\n",
    "        \n",
    "    print(\"Iterations:\")    \n",
    "    for t in range(1, iters):\n",
    "        if eta_val is None:\n",
    "            eta = 1/(np.sqrt(n*t))\n",
    "            \n",
    "        if t%200 == 0:\n",
    "            print(t)\n",
    "        \n",
    "        zhat = np.matmul(x,theta[t-1])\n",
    "        costs = (zhat-z)*(1-2*y)\n",
    "        \n",
    "        prc = LinearRegression(fit_intercept=False).fit(x,costs)\n",
    "        h_real = prc.predict(x)\n",
    "        h_plus = h_real > 0\n",
    "        h_minus = h_real < 0\n",
    "    \n",
    "        if np.sum(costs[h_plus]) > -np.sum(costs[h_minus]):\n",
    "            h = h_plus\n",
    "        else:\n",
    "            h = h_minus\n",
    "            \n",
    "        h = h.astype(int)\n",
    "        zhat_sum = np.sum(zhat)\n",
    "        err_points = np.abs(h-y)\n",
    "        \n",
    "        err_cost = np.squeeze(np.matmul((zhat-z).T,err_points))/n\n",
    "        overall_diff = zhat_sum/z_sum - 1\n",
    "\n",
    "        if np.abs(overall_diff) >= np.abs(err_cost):           \n",
    "            penalty = np.sign(overall_diff) * grad_term_overall\n",
    "        else:\n",
    "            penalty = np.sign(err_cost) * np.matmul(np.transpose(x),err_points)/n\n",
    "        \n",
    "        #breakpoint()\n",
    "        #New dot product objective\n",
    "        if non_disclosive:\n",
    "            dot_objective = np.matmul(np.transpose(x),z)/n\n",
    "            penalty = penalty.reshape(-1,1) + dot_objective.reshape(-1,1)\n",
    "        elif MSE:\n",
    "            objective = 2*np.matmul(np.transpose(x),(zhat-z))/n\n",
    "            penalty = penalty.reshape(-1,1) + objective.reshape(-1,1)\n",
    "        else:\n",
    "            penalty = penalty.reshape(-1,1)\n",
    "        \n",
    "        new_theta = theta[t-1] - eta*penalty\n",
    "        #new_theta = theta[t-1] - eta*penalty.reshape(-1,1)\n",
    "        theta.append(new_theta)\n",
    "        theta_average.append((t*theta_average[t-1]+new_theta)/(t+1))\n",
    "        \n",
    "        if t%100 == 0 :\n",
    "            if has_converged(theta_average, 10, epsilon):\n",
    "                converged = True\n",
    "                break\n",
    "                    \n",
    "    return theta, theta_average[-1]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "037df28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_proxy(x, y, z, theta_average):\n",
    "    n = x.shape[0]\n",
    "    zhat = np.matmul(x, theta_average) \n",
    "    final_costs = (zhat-z)*(1-2*y)\n",
    "    prc = LinearRegression(fit_intercept=False).fit(x, final_costs)  \n",
    "    h_real = prc.predict(x)\n",
    "    h_plus = h_real > 0\n",
    "    h_minus = h_real < 0\n",
    "    \n",
    "    if np.sum(h_real[h_plus]) > -np.sum(h_real[h_minus]):\n",
    "        h = h_plus\n",
    "    else:\n",
    "        h = h_minus\n",
    "    \n",
    "    h = h.astype(int)    \n",
    "       \n",
    "    zhat_sum = np.sum(zhat)\n",
    "    z_sum = np.sum(z)\n",
    "    err_points = np.abs(h-y)\n",
    "\n",
    "    err_cost_z = np.squeeze(np.matmul(z.T, err_points))\n",
    "    err_cost_zhat = np.squeeze(np.matmul(zhat.T, err_points))\n",
    "    overall_diff = zhat_sum/z_sum - 1\n",
    "    model_diff = (err_cost_zhat - err_cost_z)/n\n",
    "    proxy_error = err_cost_zhat/zhat_sum - err_cost_z/z_sum\n",
    "    \n",
    "    return overall_diff, model_diff, proxy_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89db7ed",
   "metadata": {},
   "source": [
    "I. Census Data Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bdafc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = ACSDataSource(survey_year='2018', horizon='1-Year', survey='person')\n",
    "acs_data = data_source.get_data(states=[\"CA\"], download=False)\n",
    "features, label, group = ACSEmployment.df_to_numpy(acs_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e12664f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filename = \"ACS.npz\"\n",
    "#np.savez(filename, X = x, Y = y.flatten(), grouplabels = z.T, group_sets = [\"White\", \"Black\"], group_types = \"Race\", is_binary = True, proxy = np.matmul(x, theta_average))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46954e3f",
   "metadata": {},
   "source": [
    "II. Synthetic Data Experimental Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "434c4dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthetic_proxy_experiments(T, trials, n, d, epsilon, eta, unit=False):\n",
    "    discrepancy_proxy = []\n",
    "    discrepancy_total = []\n",
    "    discrepancy_h = []\n",
    "    intercept = np.ones(n).reshape(-1,1)\n",
    "    \n",
    "    for i in range(0,trials):\n",
    "        np.random.seed(i)\n",
    "        y = np.round(np.random.rand(n,1))\n",
    "        \n",
    "        if unit:\n",
    "            theta = np.random.rand(d,1)\n",
    "            theta = theta/np.linalg.norm(theta)\n",
    "            x = np.random.rand(n,d)\n",
    "            \n",
    "            for j in range(0,n):\n",
    "                x[j,:] = x[j,:]/np.linalg.norm(x[j,:])\n",
    "                \n",
    "            zhat = np.matmul(x,theta)\n",
    "            z = np.random.binomial(n=n,p=zhat)   \n",
    "            \n",
    "        else:\n",
    "            z = np.round(np.random.rand(n,n))\n",
    "            theta = np.random.rand(n,n)\n",
    "            x = np.matmul(z, np.linalg.inv(theta))\n",
    "            x = np.hstack((intercept, x))\n",
    "            z = z[:,0].reshape(-1,1)\n",
    "\n",
    "        coefficients, theta_average = linear_proxies(x, y, z, T, epsilon, eta)\n",
    "        overall_diff, model_diff, proxy_error = evaluate_proxy(x,y,z,theta_average)\n",
    "       \n",
    "        discrepancy_total.append(overall_diff)\n",
    "        discrepancy_h.append(model_diff)\n",
    "        discrepancy_proxy.append(proxy_error)\n",
    "        \n",
    "    return discrepancy_total, discrepancy_h, discrepancy_proxy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d4ecb2",
   "metadata": {},
   "source": [
    "III. FTPL Algo (Non-Linear Proxies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba588f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_linear_proxies(x,y,z,W,T,alpha,epsilon):\n",
    "\n",
    "    model = LogisticRegression().fit(x, z.flatten())\n",
    "    zhat = [model.predict_proba(x)[:,1].reshape(-1,1)]\n",
    "    costs = 0\n",
    "    z_sum = np.sum(z)\n",
    "    n = x.shape[0]\n",
    "    \n",
    "    C = ((1+n)/(2*alpha*z_sum)) + 1\n",
    "    eta = 1/(C*np.sqrt(n*T))\n",
    "    eta_prime = z_sum/(C*n*np.sqrt(T))\n",
    "        \n",
    "    for t in range(T):\n",
    "        if (t+1)%10 == 0 :\n",
    "            if has_converged(zhat, 10, epsilon):\n",
    "                converged = True\n",
    "                print(\"Has converged\")\n",
    "                break\n",
    "                \n",
    "        costs = costs + (zhat[t]-z)*(1-2*y)\n",
    "        err_cost = []\n",
    "        \n",
    "        for _ in range(W):\n",
    "            noise = np.random.rand(n).reshape(-1,1)\n",
    "            noisy_costs = eta*costs + (2*noise-1)          \n",
    "            prc = LinearRegression().fit(x,noisy_costs)    \n",
    "            h_real = prc.predict(x)\n",
    "            h_plus = h_real > 0\n",
    "            h_minus = h_real < 0\n",
    "    \n",
    "            if np.sum(h_real[h_plus]) > -np.sum(h_real[h_minus]):\n",
    "                h = h_plus.astype(int)\n",
    "                lambda_0 = C/z_sum\n",
    "            else:\n",
    "                h = h_minus.astype(int)\n",
    "                lambda_0 = -C/z_sum\n",
    "                \n",
    "            err_points = np.abs(h-y)\n",
    "            err_cost.append(lambda_0*(zhat[t]-z)*err_points)\n",
    "\n",
    "        overall_diff = np.sum(zhat[t])/z_sum - 1\n",
    "        \n",
    "        if overall_diff < 0:\n",
    "            p = np.minimum(1,-eta_prime*overall_diff)\n",
    "        else:\n",
    "            p = 0\n",
    "        \n",
    "        weights = (2 * p - 1)*C*(zhat[t]/z_sum - 1/n) + np.mean(err_cost, axis=0)\n",
    "        if np.min(weights) < 0:\n",
    "            weights = weights - np.min(weights)\n",
    "        model = LogisticRegression().fit(x, z.flatten(), sample_weight = weights.flatten())\n",
    "        zhat.append(model.predict_proba(x)[:,1].reshape(-1,1))\n",
    "        #Can just return average across rows instead of whole list. See below.\n",
    "        \n",
    "    return zhat\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab03fb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_nonlinear_proxy(x, y, z, zhat):\n",
    "    n = x.shape[0]\n",
    "    final_costs = (zhat-z)*(1-2*y)\n",
    "    \n",
    "    prc = LinearRegression().fit(x, final_costs)  \n",
    "    h_real = prc.predict(x)\n",
    "    h_plus = h_real > 0\n",
    "    h_minus = h_real < 0\n",
    "    \n",
    "    if np.sum(h_real[h_plus]) > -np.sum(h_real[h_minus]):\n",
    "        h = h_plus\n",
    "    else:\n",
    "        h = h_minus\n",
    "    \n",
    "    h = h.astype(int)    \n",
    "       \n",
    "    zhat_sum = np.sum(zhat)\n",
    "    z_sum = np.sum(z)\n",
    "    err_points = np.abs(h-y)\n",
    "\n",
    "    err_cost_z = np.squeeze(np.matmul(z.T, err_points))\n",
    "    err_cost_zhat = np.squeeze(np.matmul(zhat.T, err_points))\n",
    "    overall_diff = zhat_sum/z_sum - 1\n",
    "    model_diff = (err_cost_zhat - err_cost_z)/z_sum\n",
    "    proxy_error = err_cost_zhat/zhat_sum - err_cost_z/z_sum\n",
    "    \n",
    "    return overall_diff, model_diff, proxy_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d125d935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:\n",
      "200\n",
      "400\n",
      "600\n",
      "800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emidiana/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 1 and the array at index 1 has size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-807f985690c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mzhat_MSE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_proxies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMSE\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorrcoef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzhat_MSE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mzhat_nd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_proxies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_disclosive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorrcoef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzhat_nd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mcorrcoef\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mcorrcoef\u001b[0;34m(x, y, rowvar, bias, ddof)\u001b[0m\n\u001b[1;32m   2549\u001b[0m         warnings.warn('bias and ddof have no effect and are deprecated',\n\u001b[1;32m   2550\u001b[0m                       DeprecationWarning, stacklevel=3)\n\u001b[0;32m-> 2551\u001b[0;31m     \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcov\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrowvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2552\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2553\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mcov\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mcov\u001b[0;34m(m, y, rowvar, bias, ddof, fweights, aweights)\u001b[0m\n\u001b[1;32m   2413\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrowvar\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2414\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2415\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2417\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mddof\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 1 and the array at index 1 has size 2"
     ]
    }
   ],
   "source": [
    "bw_indices = group < 3\n",
    "\n",
    "X_train, X_test, y_train, y_test, group_train, group_test = train_test_split(\n",
    "    features[bw_indices,:], label[bw_indices], group[bw_indices]-1, test_size=0.01, random_state=0)\n",
    "\n",
    "y = y_train.astype(int).reshape(-1,1)\n",
    "z = group_train.reshape(-1,1)\n",
    "x = X_train[:,:-1]/np.max(X_train[:,:-1])\n",
    "\n",
    "zhat_MSE = linear_proxies(x, y, z, 1000, epsilon = 0, MSE=True)\n",
    "breakpoint()\n",
    "print(np.corrcoef(z, np.mean(zhat_MSE[0]))\n",
    "zhat_nd = linear_proxies(x, y, z, 1000, epsilon = 0, non_disclosive=True)\n",
    "print(np.corrcoef(z, zhat_nd))\n",
    "zhat_none = linear_proxies(x, y, z, 1000, epsilon = 0)\n",
    "print(np.corrcoef(z, zhat_none))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee84d208",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_diff, model_diff, proxy_error = evaluate_proxy(x, y, z, np.mean(zhat_MSE[0], axis=0))\n",
    "    \n",
    "print(\"Overall diff: \" + str(overall_diff))\n",
    "print(\"Model diff: \" + str(model_diff))\n",
    "print(\"Proxy error: \" + str(proxy_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06831ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_diff, model_diff, proxy_error = evaluate_proxy(x, y, z, np.mean(zhat_nd[0], axis=0))\n",
    "    \n",
    "print(\"Overall diff: \" + str(overall_diff))\n",
    "print(\"Model diff: \" + str(model_diff))\n",
    "print(\"Proxy error: \" + str(proxy_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f00a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_diff, model_diff, proxy_error = evaluate_proxy(x, y, z, np.mean(zhat_none[0], axis=0))\n",
    "    \n",
    "print(\"Overall diff: \" + str(overall_diff))\n",
    "print(\"Model diff: \" + str(model_diff))\n",
    "print(\"Proxy error: \" + str(proxy_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d274be",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.matmul(x, np.mean(zhat_none[0], axis = 0)) -z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68ee406",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.matmul(x, np.mean(zhat_nd[0], axis = 0)) -z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155f8050",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.matmul(x, np.mean(zhat_MSE[0], axis = 0)) -z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37a324ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ff6c176",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-c3aeed822cba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzhat_MSE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "print(zhat_MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf25e121",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bw_indices = (group<3)\n",
    "\n",
    "#X_train, X_test, y_train, y_test, group_train, group_test = train_test_split(\n",
    "#    features[bw_indices,:], label[bw_indices], group[bw_indices]-1, test_size=0.30, random_state=0)\n",
    "\n",
    "#y = y_train.astype(int).reshape(-1,1)\n",
    "#z = group_train.reshape(-1,1)\n",
    "#x = X_train[:,:-1]/np.max(X_train[:,:-1])\n",
    "\n",
    "#for deg in range(1,10):\n",
    "#\n",
    "#    poly_reg=PolynomialFeatures(degree=deg)\n",
    "#    x_poly = poly_reg.fit_transform(x)\n",
    "#    coefficients, theta_average = linear_proxies(x_poly, y, z, 1000, 0.01)\n",
    "#    overall_diff, model_diff, proxy_error = evaluate_proxy(x_poly, y, z, theta_average)\n",
    "#    \n",
    "#    print(\"Polynomial Degree: \" + str(deg))\n",
    "#    print(\"Overall diff: \" + str(overall_diff))\n",
    "#    print(\"Model diff: \" + str(model_diff))\n",
    "#    print(\"Proxy error: \" + str(proxy_error))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
