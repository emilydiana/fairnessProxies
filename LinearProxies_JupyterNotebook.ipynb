{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_costs(x, y, z, theta):\n",
    "    costs = (np.matmul(x,theta)-z)*(1-2*y)\n",
    "    return costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paired_classifier(x, costs):\n",
    "    f = []\n",
    "    for cost in costs.T:\n",
    "        f.append(LinearRegression().fit(x, cost))\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obj_grad(objective, x, z, theta, n):\n",
    "    if objective=='MSE':\n",
    "        grad = 2*np.matmul(x.T,np.matmul(x,theta)-z)/n\n",
    "        return grad.flatten()\n",
    "    elif objective=='dot_product':\n",
    "        grad = np.matmul(x.T,z)/n\n",
    "        return grad.flatten()\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_proxies(x, y, z_all, C, iters, n, K, objective=None):\n",
    "    theta_list = []\n",
    "    grad_list = []\n",
    "    for k in range(0,K):\n",
    "        z = z_all[:,k].reshape(-1,1)\n",
    "        zhat = LinearRegression().fit(x, z)\n",
    "        theta = [np.transpose(zhat.coef_)]\n",
    "        grad_l = []\n",
    "        for t in range(1, iters):\n",
    "            costs = linear_costs(x, y, z, theta[t-1])\n",
    "            f_s = paired_classifier(x, costs)\n",
    "            val = []\n",
    "            h= [0]*n\n",
    "            for i, f in enumerate(f_s):\n",
    "                h_s = f.predict(x)\n",
    "                h[i] = h_s < 0\n",
    "                val.append(np.sum(h_s[h[i]]))\n",
    "            y_index = np.argmin(val)\n",
    "            y_temp = y[:,y_index]\n",
    "            h = h[y_index].astype(int)\n",
    "            if np.abs((np.sum(np.matmul(x,theta[t-1]))/np.sum(z)) - 1) >= np.abs(np.matmul((np.matmul(x,theta[t-1])-z).T,np.abs(h-y_temp))):\n",
    "                penalty = np.sign((np.sum(np.matmul(x,theta[t-1]))/np.sum(z)) - 1) * np.sum(x, axis=0)/np.sum(z)\n",
    "            else:\n",
    "                penalty = np.sign(np.matmul(np.transpose(np.matmul(x,theta[t-1])-z),np.abs(h-y_temp))) * np.matmul(np.transpose(x),np.abs(h-y_temp))  \n",
    "                penalty = penalty.flatten()\n",
    "            grad_l.append(obj_grad(objective,x,z,theta[t-1],n) + C * penalty) \n",
    "            theta.append(theta[t-1] - (np.power(t, -1/2) * grad_l[t-1]).reshape(-1,1))\n",
    "        theta_list.append(theta)\n",
    "        grad_list.append(grad_l)\n",
    "    return theta_list, grad_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_hyperparameter_C(z, n, M, alpha):\n",
    "    C = (np.square(M)+2*(alpha*np.sum(z)/(1+n*M)))/(alpha*np.sum(z)/(1+n*M))\n",
    "    return C\n",
    "\n",
    "def calculate_hyperparameter_T(d, B, C, M, alpha, z, n):\n",
    "    T = ((d+1)**4)*np.square(2*M*B+n*C*B*(alpha*np.sum(z)/(1+n*M)))/np.square((alpha*np.sum(z)/(1+n*M)))\n",
    "    return int(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.0247473 ]\n",
      " [ 1.90317126]\n",
      " [-0.55915006]\n",
      " [-0.02158553]\n",
      " [ 0.04872278]\n",
      " [ 0.4720086 ]\n",
      " [ 1.0629163 ]\n",
      " [-0.88641109]\n",
      " [ 0.61624987]\n",
      " [ 0.77058634]]\n",
      "[[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.81718092]\n",
      " [1.11807189]\n",
      " [0.62195186]\n",
      " [0.79989688]\n",
      " [0.77482655]\n",
      " [0.90867143]\n",
      " [0.44865083]\n",
      " [0.69026599]\n",
      " [1.16268301]\n",
      " [0.55370212]]\n",
      "[[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]]\n",
      "[[0.43709225]\n",
      " [0.75758218]\n",
      " [0.49410062]\n",
      " [1.45623375]\n",
      " [1.25629574]\n",
      " [0.8831517 ]\n",
      " [1.15357769]\n",
      " [1.65576589]\n",
      " [0.1417099 ]\n",
      " [1.01673458]]\n",
      "[[1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "[[ 1.89423604]\n",
      " [ 3.38232204]\n",
      " [-0.43629074]\n",
      " [ 0.00711529]\n",
      " [ 2.43486353]\n",
      " [ 1.32690066]\n",
      " [ 0.08205358]\n",
      " [-0.01464153]\n",
      " [ 2.67693093]\n",
      " [-1.22156799]]\n",
      "[[0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "# np.random.seed(1) #Good\n",
    "np.random.seed(2) #Bad\n",
    "\n",
    "n = 10\n",
    "m = 1\n",
    "K = 1\n",
    "d = 1\n",
    "\n",
    "M = 2\n",
    "B = 1\n",
    "alpha = 0.3\n",
    "\n",
    "trials = 10\n",
    "intercept = np.ones(n).reshape(-1,1)\n",
    "discrepancy = []\n",
    "\n",
    "for i in range(0,trials):\n",
    "    x_train = np.random.rand(n,d)\n",
    "    x_train = np.hstack((intercept, x_train))\n",
    "    y_train = np.round(np.random.rand(n,m))\n",
    "    z_train = np.round(np.random.rand(n,K))\n",
    "    \n",
    "    C = calculate_hyperparameter_C(z_train, n, M, alpha)\n",
    "    T = calculate_hyperparameter_T(d, B, C, M, alpha, z_train, n)\n",
    "\n",
    "    coefficients, gradients = linear_proxies(x_train, y_train, z_train, C, T, n, K)\n",
    "\n",
    "    final_model = np.mean(coefficients, axis=1)\n",
    "    final_costs = linear_costs(x_train, y_train, z_train, final_model)\n",
    "    prc = paired_classifier(x_train, final_costs)\n",
    "    h_s = prc[0].predict(x_train)\n",
    "    h = h_s < 0\n",
    "    h_int = h.astype(int)\n",
    "    h_err = h_int != y_train\n",
    "    z_hat = np.matmul(x_train, final_model[0])\n",
    "    print(z_hat)\n",
    "    print(z_train)\n",
    "    #Check discrepancy\n",
    "    discrepancy.append(np.mean(z_train[h_err])/(np.mean(z_train)) - np.mean(z_hat[h_err])/(np.mean(z_hat)))\n",
    "    \n",
    "print(discrepancy)\n",
    "print(np.mean(discrepancy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 0., 0., 0., 1., 3., 2., 0., 1., 2.]),\n",
       " array([-0.99893649, -0.82265711, -0.64637772, -0.47009834, -0.29381896,\n",
       "        -0.11753957,  0.05873981,  0.23501919,  0.41129858,  0.58757796,\n",
       "         0.76385734]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(discrepancy)\n",
    "\n",
    "#Portion of discrepancies that fall in good range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients_0 = [row[0] for row in coefficients[0]]\n",
    "plt.plot(coefficients_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients_1 = [row[2] for row in coefficients[1]]\n",
    "plt.plot(coefficients_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradients_0 = [row[0] for row in gradients[0]]\n",
    "plt.plot(gradients_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradients_1 = [row[1] for row in gradients[1]]\n",
    "plt.plot(gradients_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.random.seed(1)\n",
    "n = 100\n",
    "m = 1\n",
    "K = 3\n",
    "d = 2\n",
    "intercept = np.ones(n).reshape(-1,1)\n",
    "x_train = np.random.rand(n,d)\n",
    "x_train = np.hstack((intercept, x_train))\n",
    "y_train = np.round(np.random.rand(n,m))\n",
    "z_train = np.round(np.random.rand(n,K))\n",
    "\n",
    "\n",
    "nonlinear_proxies(x_train, y_train, z_train, 1, 100000, 10, 100, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def nonlinear_proxies(x, y, z_all, C, T, W, n, K, objective=None):\n",
    "    zhat_list = []\n",
    "    for t in range(0,T):\n",
    "        noise = np.random.rand(n,W)\n",
    "        for w in range(0,W):\n",
    "            noise_w = noise[:,w]\n",
    "            Basically find lambda the same way"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
